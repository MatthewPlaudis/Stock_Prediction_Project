{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewPlaudis/Stock_Prediction_Project/blob/main/Sentiment_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfcTuLRKHhxx"
      },
      "source": [
        "#These functions were implemented for the layout of wsj file\n",
        "#modifications will be needed if other layout formats are used\n",
        "\n",
        "#Either modify the code (prefered method) such that the files are uploaded the way MA demonstrated or\n",
        "#manually upload wsj, and the dictionary MA linked on discord, to colab\n",
        "#rename the dictionary to 'master.csv'\n",
        "#rename s&p500_with_labels to 's&p.csv'\n",
        "\n",
        "#Pay no attention to my verbose 'brute force' implementation in places, I try to avoid python as much as \n",
        "#possible and therefore crafty pythonic list manipulations often elude me\n",
        "\n",
        "\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import csv\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RKba5Y3rWK"
      },
      "source": [
        "#new word list for modified vader\n",
        "new_words = \n",
        "{'rise': 10,'rising': 10,'rises': 10,'fall': -10,'falls': -10,'beats': 5,\n",
        " 'crashing': -200,'crashes': -200, 'crashed': -200,'sores': 100,'breaks': 50,\n",
        " 'surge': 100, 'surges': 100,'losses': -100,'drops': -50,'bear': -20, \n",
        " 'bull': 20, 'decline': -30,'recover': 30,'recovering': 30,'raises': 10,\n",
        " 'tougher': -10,'beating': -50,'down': -30,'below': -30,'sinks': -30,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tu9DYtFGJ_-"
      },
      "source": [
        "#word dictionary functions\n",
        "\n",
        "def getDict():\n",
        "  #load word Dictionary\n",
        "  with open('master.csv', newline='') as f:\n",
        "     reader = csv.reader(f)\n",
        "     wordDict = list(reader)\n",
        "\n",
        "#clean wordDict\n",
        "  wordDictCleaned = {}\n",
        "  for i in range (1,len(wordDict)):\n",
        "   wordDictCleaned[wordDict[i][0]] = int(wordDict[i][8])-int(wordDict[i][7])\n",
        "\n",
        "  return wordDictCleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNiNgiZr_hOu"
      },
      "source": [
        "#wsj functions \n",
        "\n",
        "#reads and cleans wsj\n",
        "def getWSJ():\n",
        "  #input wsj\n",
        "  with open('wsj.csv', newline='') as f:\n",
        "     reader = csv.reader(f)\n",
        "     wsj = list(reader)\n",
        "\n",
        "  #clean wsj\n",
        "  wsjCleanedtemp = []\n",
        "  for i in range(1,len(wsj)):\n",
        "   wsjCleanedtemp.append(wsj[i][1])\n",
        "\n",
        "  #remove ';'\n",
        "  wsjCleaned = []\n",
        "  for i in range(0,len(wsjCleanedtemp)):\n",
        "   hold = wsjCleanedtemp[i].replace(';',' ')\n",
        "   wsjCleaned.append(hold)\n",
        "\n",
        "  return wsjCleaned\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# compile wsj news headings and its sentiment\n",
        "def joinSent(wsjSentiment,wsjCleaned):\n",
        "  combined = [['wsj News','sentiment']]\n",
        "  for i in range (0,len(wsjSentiment)):\n",
        "   hold = []\n",
        "   hold.append(wsjCleaned[i])\n",
        "   hold.append(wsjSentiment[i])\n",
        "   combined.append(hold)\n",
        "  return combined\n",
        "\n",
        "\n",
        "\n",
        "#calculates sentiment\n",
        "#chooser ==1: modified, chooser==2: wordDict, else OOB\n",
        "def calc_wsj_sent(chooser,new_words,wordDictCleaned,wsjCleaned):\n",
        "  wsjSentiment = []\n",
        "  analyzer = SentimentIntensityAnalyzer()\n",
        "  name = 'OOB'\n",
        "\n",
        "  #modified\n",
        "  if (chooser == 1):\n",
        "    analyzer.lexicon.update(new_words)\n",
        "    name = 'modified'\n",
        "  \n",
        "  #Worddict\n",
        "  if (chooser==2):\n",
        "    analyzer.lexicon.update(wordDictCleaned)\n",
        "    name = 'wordDict'\n",
        "\n",
        "  for i in range (0,len(wsjCleaned)):\n",
        "    temp = analyzer.polarity_scores(wsjCleaned[i])\n",
        "    wsjSentiment.append(temp.get('pos')-temp.get('neg'))\n",
        "  \n",
        "  #combine wsj and its sentiment\n",
        "  joined = joinSent(wsjSentiment, wsjCleaned)\n",
        "\n",
        "  #save wsj to file\n",
        "  file = open('wsj_with_'+name+'_sentiment.csv','w+',newline = '')\n",
        "  with file:\n",
        "    write = csv.writer(file)\n",
        "    write.writerows(joined)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMTyGFB-HAdw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y1O3fwEW-R9"
      },
      "source": [
        "#functions for calculating wsj with OOB sent and s&p\n",
        "\n",
        "def getFiles():\n",
        "  #input s&p\n",
        "  with open('s&p.csv', newline='') as f:\n",
        "     reader = csv.reader(f)\n",
        "     sAndP = list(reader)\n",
        "\n",
        "\n",
        "  #input wsjOOB\n",
        "  with open('wsj_with_OOB_sentiment.csv', newline='') as f:\n",
        "     reader = csv.reader(f)\n",
        "     wsjOOB = list(reader)\n",
        "\n",
        "\n",
        "  #input wsj\n",
        "  with open('wsj.csv', newline='') as f:\n",
        "     reader = csv.reader(f)\n",
        "     wsj = list(reader)\n",
        "\n",
        "  return sAndP,wsjOOB,wsj\n",
        "\n",
        "\n",
        "#join wsj and wsjOOB together\n",
        "def joinWSJ(wsj,wsjOOB):\n",
        "  grouped = []\n",
        "  for i in range (1,len(wsj)):\n",
        "    temp = []\n",
        "    temp.append(wsj[i][0])\n",
        "    temp.append(wsjOOB[i][0])\n",
        "    temp.append(wsjOOB[i][1])\n",
        "    grouped.append(temp)\n",
        "\n",
        "  return grouped\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#calculate averages per day\n",
        "def calcAvg(grouped):\n",
        "  hold = grouped[0][0]\n",
        "  sumUp = float(grouped[0][2])\n",
        "  count = 1\n",
        "  groupedAvg = []\n",
        "  for i in range(1,len(grouped)):\n",
        "    if grouped[i][0] == hold:\n",
        "     #keep averaging\n",
        "      sumUp = sumUp + float(grouped[i][2])\n",
        "      count = count + 1\n",
        "    else:\n",
        "      #save avg\n",
        "      temp = []\n",
        "      temp.append(hold)\n",
        "      temp.append(sumUp/count)\n",
        "      groupedAvg.append(temp)\n",
        "      #reset\n",
        "      hold = grouped[i][0]\n",
        "      count = 1\n",
        "      sumUp = float(grouped[i][2])\n",
        "  return groupedAvg\n",
        "\n",
        "\n",
        "\n",
        "#clean sAndP\n",
        "def clean(sAndP):\n",
        "  sAndPCleaned = []\n",
        "  for i in range (2,len(sAndP)):\n",
        "    sAndPCleaned.append(sAndP[i])\n",
        "  return sAndPCleaned\n",
        "\n",
        "\n",
        "\n",
        "#join by date\n",
        "def join_up(sAndPCleaned,groupedAvg):\n",
        "  sameDate = []\n",
        "  hold= []\n",
        "  hold.append('Date')\n",
        "  hold.append('Open')\n",
        "  hold.append('Adj Close')\n",
        "  hold.append('Volume')\n",
        "  hold.append(\"avg'd sentiment\")\n",
        "  hold.append('label')\n",
        "  sameDate.append(hold)\n",
        "  for i in range(0,len(sAndPCleaned)):\n",
        "    for j in range(0,len(groupedAvg)):\n",
        "      if sAndPCleaned[i][1] == groupedAvg[j][0]:\n",
        "        temp = []\n",
        "        temp.append(sAndPCleaned[i][1])\n",
        "        temp.append(sAndPCleaned[i][2])\n",
        "        temp.append(sAndPCleaned[i][6])\n",
        "        temp.append(sAndPCleaned[i][7])\n",
        "        temp.append(groupedAvg[j][1])\n",
        "        temp.append(sAndPCleaned[i][8])\n",
        "        sameDate.append(temp)\n",
        "  \n",
        "  return sameDate\n",
        "\n",
        "\n",
        "\n",
        "#save wsj sentiment combined with s&p to file\n",
        "def saveFile(sameDate):\n",
        "  file = open('wsj_OOBsent_s&p.csv','w+',newline = '')\n",
        "  with file:\n",
        "    write = csv.writer(file)\n",
        "    write.writerows(sameDate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgUnQSf_MR2h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nxep8yYLXXG"
      },
      "source": [
        "#MAIN CODE STARTS HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhzjHP2LFzoA"
      },
      "source": [
        "#calc raw sentiment files\n",
        "\n",
        "#get cleaned word dict\n",
        "wordDictCleaned = getDict()\n",
        "#get cleaned wsj\n",
        "wsjCleaned = getWSJ()\n",
        "\n",
        "\n",
        "#sent_type == 1: modified, sent_type == 2: wordDict, else OOB\n",
        "sent_type = 0;\n",
        "\n",
        "\n",
        "#calculate and write to file\n",
        "calc_wsj_sent(sent_type,new_words,wordDictCleaned,wsjCleaned)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6-bdNUzLfft"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T14cy_DH6WZ"
      },
      "source": [
        "#calc s&p with wsj and OOB sent\n",
        "\n",
        "#read in files\n",
        "sAndP, wsjOOB, wsj = getFiles()\n",
        "#join wsj and wsjOOB\n",
        "grouped = joinWSJ(wsj,wsjOOB)\n",
        "#calc average sent per day\n",
        "groupedAvg = calcAvg(grouped)\n",
        "#clean s&p\n",
        "sAndPCleaned = clean(sAndP)\n",
        "#join s&p with avg sent\n",
        "sameDate = join_up(sAndPCleaned,groupedAvg)\n",
        "#save file\n",
        "saveFile(sameDate)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}